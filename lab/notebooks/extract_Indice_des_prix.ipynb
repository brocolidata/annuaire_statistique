{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract & Load *Indice des prix* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import dictconfig\n",
    "from omegaconf import OmegaConf\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_NAME = \"indice_des_prix\"\n",
    "SOURCE_SETTINGS_PATH = pathlib.Path('/dataplatform_lab', 'lab', 'notebooks', 'sources')\n",
    "DATA_PATH = pathlib.Path('/dataplatform_lab', 'lab', 'dwh_data')\n",
    "EXTRACTS_PATH = pathlib.Path(DATA_PATH, 'extracts')\n",
    "LOAD_PATH = pathlib.Path(DATA_PATH, 'raw')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config() -> dictconfig.DictConfig:\n",
    "    config_path = SOURCE_SETTINGS_PATH.relative_to(os.getcwd()).as_posix()\n",
    "    with initialize(\n",
    "        version_base=None, \n",
    "        config_path=config_path\n",
    "    ):\n",
    "        return compose(config_name=CONFIG_NAME)\n",
    "\n",
    "\n",
    "def get_available_year(historic_years, year):\n",
    "    return list(range(year-1, year-(historic_years+1), -1))\n",
    "\n",
    "\n",
    "def get_years_to_load(historic_years, years):\n",
    "    years.sort(reverse=True)\n",
    "    dc_available_years = {\n",
    "        y:get_available_year(historic_years, y) for y in years\n",
    "    }\n",
    "    dc_years = {}\n",
    "    for year in years:\n",
    "        dc = {\n",
    "            ay:year for ay in dc_available_years[year] if ay not in dc_years\n",
    "        }\n",
    "        dc_years.update(dc)\n",
    "    return dc_years\n",
    "\n",
    "\n",
    "def get_excel_file(folder_path: pathlib.Path, excel_file_name: str) -> pd.ExcelFile:\n",
    "    excel_file_path = pathlib.Path(folder_path, excel_file_name)\n",
    "    return pd.ExcelFile(excel_file_path)\n",
    "\n",
    "\n",
    "def process_column_names(\n",
    "    df: pd.DataFrame,\n",
    "    dimension_cols: None | list = None,\n",
    "    dimension_cols_rename: None | list  = None\n",
    "):\n",
    "    rename_dc = {}\n",
    "    value_cols = df.columns.difference(dimension_cols)\n",
    "    if dimension_cols_rename:\n",
    "        rename_dc.update(\n",
    "            {\n",
    "                old:new for old, new in zip(\n",
    "                    dimension_cols, dimension_cols_rename\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    for col in value_cols:\n",
    "        renamed_col = ' '.join([x for x in re.findall(r\"[^\\W]*\",str(col)) if x])\n",
    "        rename_dc.update({col: renamed_col})\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .rename(columns=rename_dc)\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_multiline_labels(\n",
    "        df: pd.DataFrame,\n",
    "        dimension_cols: list\n",
    "    ) -> pd.DataFrame:\n",
    "    col_years=list(df.columns.difference(dimension_cols))\n",
    "    ls_produits = []\n",
    "    previous = {}\n",
    "    for i, row in df.iterrows():\n",
    "        row_dc = row.to_dict()\n",
    "        actual = {col:row_dc[col] for col in dimension_cols}\n",
    "        elem = row_dc[col_years[0]]\n",
    "        if pd.isna(elem):\n",
    "            previous = actual\n",
    "        elif previous:\n",
    "            ls_produits.append(\n",
    "                {\n",
    "                    col:str(previous.get(col)).strip() + \"\" + str(actual.get(col)).strip() for col in dimension_cols\n",
    "                }\n",
    "            )\n",
    "            previous = {}\n",
    "        else:\n",
    "\n",
    "            ls_produits.append(\n",
    "                { \n",
    "                    col:str(actual.get(col)).strip() for col in dimension_cols \n",
    "                }\n",
    "            )\n",
    "            previous = {}\n",
    "\n",
    "    df_produits = pd.DataFrame(ls_produits)\n",
    "    \n",
    "    # clean values\n",
    "    df_values = (\n",
    "        df[col_years]\n",
    "        .dropna(\n",
    "            axis=0,\n",
    "            how='any',\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    return pd.concat([df_produits, df_values], axis=1)\n",
    "\n",
    "\n",
    "def prepare_df(config, df:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    dimension_cols = df.columns[config.dimension_cols_index]\n",
    "    clean_col_df = process_column_names(\n",
    "        df, \n",
    "        dimension_cols=dimension_cols,\n",
    "        dimension_cols_rename=config.dimension_cols_rename\n",
    "    )\n",
    "    dimension_cols = clean_col_df.columns[config.dimension_cols_index]\n",
    "    clean_df = merge_multiline_labels(clean_col_df, dimension_cols) \n",
    "\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def save_df(df, path):\n",
    "    if not path.parent.exists():\n",
    "        path.parent.mkdir(parents=True)\n",
    "    \n",
    "    df.to_parquet(\n",
    "        path,\n",
    "        index = None\n",
    "    )\n",
    "\n",
    "\n",
    "def get_base_year(\n",
    "    excel_file: pd.io.excel._base.ExcelFile,\n",
    "    sheet_name: str,\n",
    "    base_year_cell: str,\n",
    ") -> int:\n",
    "    wb = openpyxl.load_workbook(excel_file)\n",
    "    ws = wb[sheet_name]\n",
    "    cell = ws[base_year_cell]\n",
    "    match = re.match(r\"Base\\s100\\s\\:\\s(?P<base_year>\\d{4})\", cell.value)\n",
    "    if match:\n",
    "        return match.groupdict()[\"base_year\"]\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YearFile():\n",
    "\n",
    "    def __init__(self, dataset_version, year, year_file_dict={}):\n",
    "        self.dataset_version = dataset_version\n",
    "        self.year = year\n",
    "        self.file_name = dataset_version.dataset.source.file_names_dc[year]\n",
    "        year_file_config = year_file_dict.get('config', {})\n",
    "        self.config = OmegaConf.merge(dataset_version.config, year_file_config)\n",
    "        self.raw_df = None\n",
    "        self.dimensions_df = None\n",
    "        self.prepared_df = None\n",
    "        self.available_years = [\n",
    "            str(y) for y in get_available_year(self.config.historic_years, self.year)\n",
    "        ]\n",
    "        self.years_to_load = []\n",
    "            \n",
    "\n",
    "    def load_data_as_df(self):\n",
    "        folder_path = pathlib.Path(EXTRACTS_PATH, f\"Annuaire Statistique {self.year}\")\n",
    "        file_name = self.dataset_version.dataset.source.file_names_dc[self.year]\n",
    "        excel_file = get_excel_file(folder_path, file_name)\n",
    "        self.raw_df = pd.read_excel(\n",
    "            excel_file,\n",
    "            self.config.sheet_name,\n",
    "            header=0,\n",
    "            skiprows=self.config.skiprows,\n",
    "            skipfooter=self.config.skipfooter\n",
    "        )\n",
    "        prepared_df_all_cols = prepare_df(self.config, self.raw_df)\n",
    "        self.years_to_load = self.dataset_version.years_per_file.get(self.year, [])\n",
    "        self.prepared_df = prepared_df_all_cols[self.years_to_load]\n",
    "        self.dimensions_df = prepared_df_all_cols[self.config.dimension_cols_rename]\n",
    "\n",
    "\n",
    "\n",
    "class DatasetVersion:\n",
    "\n",
    "    def __init__(self, dataset, version_dict):\n",
    "        self.dataset = dataset\n",
    "        version_config = version_dict.get('config', {})\n",
    "        self.config = OmegaConf.merge(dataset.config, version_config)\n",
    "        self.version_num = version_dict[\"version\"]\n",
    "        self.historic_years = self.config.historic_years\n",
    "        self.years_dc = version_dict[\"years\"]\n",
    "        self.years = list(self.years_dc.keys())\n",
    "        self.files_to_load = self.get_files_to_load_per_year()\n",
    "        self.years_config = self.get_years_config()\n",
    "        self.year_files = []\n",
    "        self.years_per_file = {}\n",
    "        self.process_year_files()\n",
    "\n",
    "\n",
    "    def process_year_files(self):\n",
    "        for year, year_file_dict in self.years_dc.items():\n",
    "            year_file_dict = year_file_dict or {}\n",
    "            year_file = YearFile(self, year, year_file_dict)\n",
    "            self.year_files.append(year_file)\n",
    "        self.year_files.sort(key=lambda x: x.year, reverse=True)\n",
    "        self.years_per_file = self.get_years_per_file()\n",
    "\n",
    "\n",
    "    def get_years_per_file(self):\n",
    "        dc_years = {}\n",
    "        for year in self.year_files:\n",
    "            dc_years.update(\n",
    "                {\n",
    "                    ay:year.year for ay in year.available_years if ay not in dc_years\n",
    "                }\n",
    "            )\n",
    "        dc_years_to_load_per_file = {y:[] for y in self.years}\n",
    "        for available_year, year in dc_years.items():\n",
    "            dc_years_to_load_per_file[year].append(available_year)\n",
    "        return dc_years_to_load_per_file\n",
    "\n",
    "    \n",
    "    def get_data(self):\n",
    "        for year_file in self.year_files:\n",
    "            year_file.load_data_as_df()\n",
    "        dimensions_df = self.year_files[0].dimensions_df\n",
    "        ls_dfs = [dimensions_df, *[y.prepared_df for y in self.year_files]]\n",
    "        return pd.concat(ls_dfs,  axis=1)        \n",
    "    \n",
    "\n",
    "    @property\n",
    "    def fqtn(self):\n",
    "        return f\"{self.dataset.table_name}_v{self.version_num}\"\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.fqtn\n",
    "    \n",
    "\n",
    "    def get_files_to_load_per_year(self):\n",
    "        years_to_load_dc = get_years_to_load(\n",
    "            self.historic_years, \n",
    "            self.years\n",
    "        )\n",
    "        file_names_dc = self.dataset.source.file_names_dc\n",
    "        return {k:file_names_dc[v] for k,v in years_to_load_dc.items()}\n",
    "    \n",
    "\n",
    "    def get_years_config(self):\n",
    "        dc_config = {}\n",
    "        for year, year_dc in self.years_dc.items():\n",
    "            dc_config[year] = year_dc.config if year_dc else {}\n",
    "\n",
    "        return dc_config\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def load_path(self):\n",
    "        return pathlib.Path(\n",
    "            LOAD_PATH,\n",
    "            self.dataset.source.schema,\n",
    "            f\"{self.fqtn}.parquet\"\n",
    "        )\n",
    "\n",
    "    def load(self):\n",
    "        df = self.get_data()\n",
    "        save_df(df, self.load_path) \n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, source, dataset_dict):\n",
    "        self.source = source\n",
    "        self.name = dataset_dict.name\n",
    "        self.table_name = dataset_dict.table_name\n",
    "        self.config = dataset_dict.get('config', {})\n",
    "        self.type_data = self.config.get('type')\n",
    "        self.versions_ls = dataset_dict[\"versions\"]\n",
    "        self.versions = []\n",
    "        self.process_versions()\n",
    "\n",
    "\n",
    "    def process_versions(self):\n",
    "        for version_dict in self.versions_ls:\n",
    "            version = DatasetVersion(self, version_dict)\n",
    "            self.versions.append(version)\n",
    "\n",
    "    def extract(self):\n",
    "        for version in self.versions:\n",
    "            version.load()\n",
    "\n",
    "\n",
    "class Source:\n",
    "\n",
    "    def __init__(self, source_config):\n",
    "        self.name = source_config.name\n",
    "        self.file_names_dc = source_config.file_names\n",
    "        self.schema = source_config.schema\n",
    "        self.datasets_ls = source_config.datasets\n",
    "        self.datasets = []\n",
    "        self.process_datasets()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "    \n",
    "    def process_datasets(self):\n",
    "        dataset_iterator = tqdm(self.datasets_ls)\n",
    "        for dataset_dict in dataset_iterator:\n",
    "            dataset_iterator.set_description(dataset_dict.table_name)\n",
    "            dataset = Dataset(self, dataset_dict)\n",
    "            self.datasets.append(dataset)\n",
    "        dataset_iterator.clear()\n",
    "    \n",
    "    def extract(self):\n",
    "        for dataset in self.datasets:\n",
    "            dataset.extract()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cf1a726f894760a9cd288b6c00d57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = get_config()\n",
    "ipp_source = Source(config)\n",
    "ipp_source.extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_parquet(\n",
    "#     \"/dataplatform_lab/lab/dwh_data/raw/indice_des_prix/ipc_national_v2.parquet\"\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
